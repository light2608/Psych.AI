{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9730202-7e10-4567-8b55-c205e7cf0177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.24.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: seaborn in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.66.3)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: keras in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.13.1)\n",
      "Requirement already satisfied: tensorflow-estimator in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: librosa in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.8.1)\n",
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.9.3-cp38-cp38-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting absl-py==0.9.0\n",
      "  Using cached absl-py-0.9.0.tar.gz (104 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: appdirs==1.4.4 in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.4.4)\n",
      "Collecting audioread==2.1.9\n",
      "  Using cached audioread-2.1.9.tar.gz (377 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting cached-property==1.5.2\n",
      "  Using cached cached_property-1.5.2-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting certifi==2020.6.20\n",
      "  Using cached certifi-2020.6.20-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting cffi==1.14.2\n",
      "  Using cached cffi-1.14.2-cp38-cp38-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting chardet==3.0.4\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting cycler==0.10.0\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl.metadata (722 bytes)\n",
      "Requirement already satisfied: decorator==4.4.2 in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.4.2)\n",
      "Collecting joblib==0.16.0\n",
      "  Using cached joblib-0.16.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting kiwisolver==1.2.0\n",
      "  Using cached kiwisolver-1.2.0-cp38-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting librosa\n",
      "  Using cached librosa-0.8.0.tar.gz (183 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting llvmlite==0.33.0\n",
      "  Using cached llvmlite-0.33.0-cp38-cp38-win_amd64.whl.metadata (4.5 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.3.0-cp38-cp38-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting numba==0.50.1\n",
      "  Using cached numba-0.50.1-cp38-cp38-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.19.1-cp38-cp38-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.0.5-cp38-cp38-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting pooch==1.2.0\n",
      "  Using cached pooch-1.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting protobuf==3.12.2\n",
      "  Using cached protobuf-3.12.2-py2.py3-none-any.whl.metadata (884 bytes)\n",
      "Collecting pycparser==2.20\n",
      "  Using cached pycparser-2.20-py2.py3-none-any.whl.metadata (907 bytes)\n",
      "Collecting pyparsing==2.4.7\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting python-dateutil==2.8.1\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting pytz==2020.1\n",
      "  Using cached pytz-2020.1-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting requests==2.24.0\n",
      "  Using cached requests-2.24.0-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting resampy==0.2.2\n",
      "  Using cached resampy-0.2.2.tar.gz (323 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-0.23.1-cp38-cp38-win_amd64.whl.metadata (7.3 kB)\n",
      "Collecting scipy==1.5.2\n",
      "  Using cached scipy-1.5.2-cp38-cp38-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting six==1.15.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting soundfile==0.10.3.post1\n",
      "  Using cached SoundFile-0.10.3.post1-py2.py3.cp26.cp27.cp32.cp33.cp34.cp35.cp36.pp27.pp32.pp33-none-win_amd64.whl.metadata (11 kB)\n",
      "Collecting tensorboard==2.2.2\n",
      "  Using cached tensorboard-2.2.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting tensorboard-plugin-wit==1.7.0\n",
      "  Using cached tensorboard_plugin_wit-1.7.0-py3-none-any.whl.metadata (214 bytes)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.2.0-cp38-cp38-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting tensorflow-estimator\n",
      "  Using cached tensorflow_estimator-2.2.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting threadpoolctl==2.1.0\n",
      "  Using cached threadpoolctl-2.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.48.0-py2.py3-none-any.whl.metadata (53 kB)\n",
      "Collecting urllib3==1.25.10\n",
      "  Using cached urllib3-1.25.10-py2.py3-none-any.whl.metadata (40 kB)\n",
      "Collecting Werkzeug==1.0.1\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Collecting gast==0.3.3 (from tensorflow)\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Collecting h5py<2.11.0,>=2.10.0 (from tensorflow)\n",
      "  Using cached h5py-2.10.0-cp38-cp38-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting keras-preprocessing>=1.1.0 (from tensorflow)\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow) (0.43.0)\n",
      "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "\n",
      "The conflict is caused by:\n",
      "    The user requested scipy==1.5.2\n",
      "    scikit-learn 0.23.1 depends on scipy>=0.19.1\n",
      "    tensorflow 2.2.0 depends on scipy==1.4.1; python_version >= \"3\"\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install scikit-learn==0.23.1, scipy==1.5.2 and tensorflow==2.2.0 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas numpy scikit-learn matplotlib seaborn tqdm tensorflow keras tensorflow-estimator librosa nltk wordcloud absl-py==0.9.0 appdirs==1.4.4 audioread==2.1.9 cached-property==1.5.2 certifi==2020.6.20 cffi==1.14.2 chardet==3.0.4 cycler==0.10.0 decorator==4.4.2 joblib==0.16.0 kiwisolver==1.2.0 librosa==0.8.0 llvmlite==0.33.0 matplotlib==3.3.0 numba==0.50.1 numpy==1.19.1 pandas==1.0.5 pooch==1.2.0 protobuf==3.12.2 pycparser==2.20 pyparsing==2.4.7 python-dateutil==2.8.1 pytz==2020.1 requests==2.24.0 resampy==0.2.2 scikit-learn==0.23.1 scipy==1.5.2 six==1.15.0 soundfile==0.10.3.post1 tensorboard==2.2.2 tensorboard-plugin-wit==1.7.0 tensorflow==2.2.0 tensorflow-estimator==2.2.0 threadpoolctl==2.1.0 tqdm==4.48.0 urllib3==1.25.10 Werkzeug==1.0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed40f657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0390d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.read_csv(\"C:/Users/light/OneDrive/Desktop/PsychAI/Text Based Stress Detection/stress.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06cfe0c6-6d9a-4592-bfd6-a4a1ce574940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_id</th>\n",
       "      <th>sentence_range</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>social_timestamp</th>\n",
       "      <th>social_karma</th>\n",
       "      <th>syntax_ari</th>\n",
       "      <th>...</th>\n",
       "      <th>lex_dal_min_pleasantness</th>\n",
       "      <th>lex_dal_min_activation</th>\n",
       "      <th>lex_dal_min_imagery</th>\n",
       "      <th>lex_dal_avg_activation</th>\n",
       "      <th>lex_dal_avg_imagery</th>\n",
       "      <th>lex_dal_avg_pleasantness</th>\n",
       "      <th>social_upvote_ratio</th>\n",
       "      <th>social_num_comments</th>\n",
       "      <th>syntax_fk_grade</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>8601tu</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>33181</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1521614353</td>\n",
       "      <td>5</td>\n",
       "      <td>1.806818</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.77000</td>\n",
       "      <td>1.52211</td>\n",
       "      <td>1.89556</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "      <td>3.253573</td>\n",
       "      <td>-0.002742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assistance</td>\n",
       "      <td>8lbrx9</td>\n",
       "      <td>(0, 5)</td>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>2606</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1527009817</td>\n",
       "      <td>4</td>\n",
       "      <td>9.429737</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.69586</td>\n",
       "      <td>1.62045</td>\n",
       "      <td>1.88919</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2</td>\n",
       "      <td>8.828316</td>\n",
       "      <td>0.292857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>9ch1zh</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>38816</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1535935605</td>\n",
       "      <td>2</td>\n",
       "      <td>7.769821</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.1429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.83088</td>\n",
       "      <td>1.58108</td>\n",
       "      <td>1.85828</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "      <td>7.841667</td>\n",
       "      <td>0.011894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relationships</td>\n",
       "      <td>7rorpp</td>\n",
       "      <td>[5, 10]</td>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1516429555</td>\n",
       "      <td>0</td>\n",
       "      <td>2.667798</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.75356</td>\n",
       "      <td>1.52114</td>\n",
       "      <td>1.98848</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>4.104027</td>\n",
       "      <td>0.141671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>survivorsofabuse</td>\n",
       "      <td>9p2gbc</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1421</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1539809005</td>\n",
       "      <td>24</td>\n",
       "      <td>7.554238</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.77644</td>\n",
       "      <td>1.64872</td>\n",
       "      <td>1.81456</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>7.910952</td>\n",
       "      <td>-0.204167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>relationships</td>\n",
       "      <td>7oee1t</td>\n",
       "      <td>[35, 40]</td>\n",
       "      <td>* Her, a week ago: Precious, how are you? (I i...</td>\n",
       "      <td>1713</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1515187044</td>\n",
       "      <td>13</td>\n",
       "      <td>-1.369333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.71133</td>\n",
       "      <td>1.45301</td>\n",
       "      <td>2.00304</td>\n",
       "      <td>0.84</td>\n",
       "      <td>16</td>\n",
       "      <td>0.254444</td>\n",
       "      <td>0.552066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>9p4ung</td>\n",
       "      <td>[20, 25]</td>\n",
       "      <td>I don't have the ability to cope with it anymo...</td>\n",
       "      <td>1133</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1539827412</td>\n",
       "      <td>33</td>\n",
       "      <td>9.425478</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.65003</td>\n",
       "      <td>1.56842</td>\n",
       "      <td>1.81527</td>\n",
       "      <td>0.96</td>\n",
       "      <td>6</td>\n",
       "      <td>8.640664</td>\n",
       "      <td>-0.220370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>9nam6l</td>\n",
       "      <td>(5, 10)</td>\n",
       "      <td>In case this is the first time you're reading ...</td>\n",
       "      <td>10442</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1539269312</td>\n",
       "      <td>2</td>\n",
       "      <td>11.060675</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.79768</td>\n",
       "      <td>1.49074</td>\n",
       "      <td>1.92286</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>9.951524</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>almosthomeless</td>\n",
       "      <td>5y53ya</td>\n",
       "      <td>[5, 10]</td>\n",
       "      <td>Do you find this normal? They have a good rela...</td>\n",
       "      <td>1834</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1488938143</td>\n",
       "      <td>4</td>\n",
       "      <td>2.421912</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1111</td>\n",
       "      <td>1.1429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.71642</td>\n",
       "      <td>1.57627</td>\n",
       "      <td>1.89972</td>\n",
       "      <td>0.75</td>\n",
       "      <td>7</td>\n",
       "      <td>4.036765</td>\n",
       "      <td>0.159722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>5y25cl</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>I was talking to my mom this morning and she s...</td>\n",
       "      <td>961</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1488909516</td>\n",
       "      <td>2</td>\n",
       "      <td>0.835254</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.68891</td>\n",
       "      <td>1.44615</td>\n",
       "      <td>1.89707</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2</td>\n",
       "      <td>2.412000</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2838 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             subreddit post_id sentence_range  \\\n",
       "0                 ptsd  8601tu       (15, 20)   \n",
       "1           assistance  8lbrx9         (0, 5)   \n",
       "2                 ptsd  9ch1zh       (15, 20)   \n",
       "3        relationships  7rorpp        [5, 10]   \n",
       "4     survivorsofabuse  9p2gbc         [0, 5]   \n",
       "...                ...     ...            ...   \n",
       "2833     relationships  7oee1t       [35, 40]   \n",
       "2834              ptsd  9p4ung       [20, 25]   \n",
       "2835           anxiety  9nam6l        (5, 10)   \n",
       "2836    almosthomeless  5y53ya        [5, 10]   \n",
       "2837              ptsd  5y25cl         [0, 5]   \n",
       "\n",
       "                                                   text     id  label  \\\n",
       "0     He said he had not felt that way before, sugge...  33181      1   \n",
       "1     Hey there r/assistance, Not sure if this is th...   2606      0   \n",
       "2     My mom then hit me with the newspaper and it s...  38816      1   \n",
       "3     until i met my new boyfriend, he is amazing, h...    239      1   \n",
       "4     October is Domestic Violence Awareness Month a...   1421      1   \n",
       "...                                                 ...    ...    ...   \n",
       "2833  * Her, a week ago: Precious, how are you? (I i...   1713      0   \n",
       "2834  I don't have the ability to cope with it anymo...   1133      1   \n",
       "2835  In case this is the first time you're reading ...  10442      0   \n",
       "2836  Do you find this normal? They have a good rela...   1834      0   \n",
       "2837  I was talking to my mom this morning and she s...    961      1   \n",
       "\n",
       "      confidence  social_timestamp  social_karma  syntax_ari  ...  \\\n",
       "0       0.800000        1521614353             5    1.806818  ...   \n",
       "1       1.000000        1527009817             4    9.429737  ...   \n",
       "2       0.800000        1535935605             2    7.769821  ...   \n",
       "3       0.600000        1516429555             0    2.667798  ...   \n",
       "4       0.800000        1539809005            24    7.554238  ...   \n",
       "...          ...               ...           ...         ...  ...   \n",
       "2833    1.000000        1515187044            13   -1.369333  ...   \n",
       "2834    1.000000        1539827412            33    9.425478  ...   \n",
       "2835    1.000000        1539269312             2   11.060675  ...   \n",
       "2836    0.571429        1488938143             4    2.421912  ...   \n",
       "2837    0.571429        1488909516             2    0.835254  ...   \n",
       "\n",
       "      lex_dal_min_pleasantness  lex_dal_min_activation  lex_dal_min_imagery  \\\n",
       "0                       1.0000                  1.1250                  1.0   \n",
       "1                       1.1250                  1.0000                  1.0   \n",
       "2                       1.0000                  1.1429                  1.0   \n",
       "3                       1.0000                  1.1250                  1.0   \n",
       "4                       1.0000                  1.1250                  1.0   \n",
       "...                        ...                     ...                  ...   \n",
       "2833                    1.4000                  1.0000                  1.0   \n",
       "2834                    1.0000                  1.0000                  1.0   \n",
       "2835                    1.1250                  1.1250                  1.0   \n",
       "2836                    1.1111                  1.1429                  1.0   \n",
       "2837                    1.0000                  1.0000                  1.0   \n",
       "\n",
       "      lex_dal_avg_activation  lex_dal_avg_imagery  lex_dal_avg_pleasantness  \\\n",
       "0                    1.77000              1.52211                   1.89556   \n",
       "1                    1.69586              1.62045                   1.88919   \n",
       "2                    1.83088              1.58108                   1.85828   \n",
       "3                    1.75356              1.52114                   1.98848   \n",
       "4                    1.77644              1.64872                   1.81456   \n",
       "...                      ...                  ...                       ...   \n",
       "2833                 1.71133              1.45301                   2.00304   \n",
       "2834                 1.65003              1.56842                   1.81527   \n",
       "2835                 1.79768              1.49074                   1.92286   \n",
       "2836                 1.71642              1.57627                   1.89972   \n",
       "2837                 1.68891              1.44615                   1.89707   \n",
       "\n",
       "      social_upvote_ratio  social_num_comments  syntax_fk_grade  sentiment  \n",
       "0                    0.86                    1         3.253573  -0.002742  \n",
       "1                    0.65                    2         8.828316   0.292857  \n",
       "2                    0.67                    0         7.841667   0.011894  \n",
       "3                    0.50                    5         4.104027   0.141671  \n",
       "4                    1.00                    1         7.910952  -0.204167  \n",
       "...                   ...                  ...              ...        ...  \n",
       "2833                 0.84                   16         0.254444   0.552066  \n",
       "2834                 0.96                    6         8.640664  -0.220370  \n",
       "2835                 1.00                    1         9.951524   0.045455  \n",
       "2836                 0.75                    7         4.036765   0.159722  \n",
       "2837                 0.76                    2         2.412000   0.016667  \n",
       "\n",
       "[2838 rows x 116 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff0f868-402c-491f-aed3-78a2c7241dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\light\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2ee39e0-d5b8-4eab-92d1-3872429ba62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (4.66.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\light\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "795c5ee4-a8f6-429f-899a-abb92c2847bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a1352fb-1428-4cd7-ad89-33d9087fb807",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff5893a9-b63e-49c9-b440-d0d14c1acb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text\n",
    "data[\"text\"] = data[\"text\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65ec4172-faf3-49b3-973f-9454d393442e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud, STOPWORDS, ImageColorGenerator\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aab683b7-719a-4ca3-90f5-18e1ca6d1ce9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud, STOPWORDS\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mtext)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text = \" \".join(i for i in data.text)\n",
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(stopwords=stopwords, \n",
    "                      background_color=\"white\").generate(text)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff7e07db-2c89-449e-bebf-83f195841e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"label\"]=data[\"label\"].map({0:\"No Stress\",1:\"Stress\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d3dcdb1-aa4f-44de-ac27-0c451de08c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[[\"text\",\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8edc337e-37b3-41eb-b775-edf15531bcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said felt way sugget go rest trigger ahead you...</td>\n",
       "      <td>Stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey rassist sure right place post goe  im curr...</td>\n",
       "      <td>No Stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom hit newspap shock would know dont like pla...</td>\n",
       "      <td>Stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>met new boyfriend amaz kind sweet good student...</td>\n",
       "      <td>Stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>octob domest violenc awar month domest violenc...</td>\n",
       "      <td>Stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>week ago precious ignor  jan  happi year prec...</td>\n",
       "      <td>No Stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>dont abil cope anymor im tri lot thing trigger...</td>\n",
       "      <td>Stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>case first time your read post look peopl will...</td>\n",
       "      <td>No Stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>find normal good relationship main problem see...</td>\n",
       "      <td>No Stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>talk mom morn said sister trauma wors mine did...</td>\n",
       "      <td>Stress</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2838 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text      label\n",
       "0     said felt way sugget go rest trigger ahead you...     Stress\n",
       "1     hey rassist sure right place post goe  im curr...  No Stress\n",
       "2     mom hit newspap shock would know dont like pla...     Stress\n",
       "3     met new boyfriend amaz kind sweet good student...     Stress\n",
       "4     octob domest violenc awar month domest violenc...     Stress\n",
       "...                                                 ...        ...\n",
       "2833   week ago precious ignor  jan  happi year prec...  No Stress\n",
       "2834  dont abil cope anymor im tri lot thing trigger...     Stress\n",
       "2835  case first time your read post look peopl will...  No Stress\n",
       "2836  find normal good relationship main problem see...  No Stress\n",
       "2837  talk mom morn said sister trauma wors mine did...     Stress\n",
       "\n",
       "[2838 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b31687a2-34a4-416f-a36f-a95bf6e9e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1bd431a-d154-49ce-8dac-faa59e22d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(data[\"text\"])\n",
    "y=np.array(data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ebed367-1407-457e-835b-7300819d8735",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(x)\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8f48539-b132-4609-8947-78d19fa7450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01d6bfa9-46a9-4c08-a9d2-410e68ed3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f19fc021-69b9-424a-bb0c-a885ccac2556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6b79928-2e42-4fc5-ad1c-17e794ccfea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text i am not feeling well\n"
     ]
    }
   ],
   "source": [
    "user = input(\"Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53043a46-42e5-4455-bd4e-7b65d404f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=cv.transform([user]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bdd346f-4df6-460c-b1a8-a5e0dcbf8ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8cdcf2f-49a4-46b5-9b1d-3fda5a8e5b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No Stress'], dtype='<U9')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e45f0-75a0-4a3c-83af-d360962275e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
